{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/hccl.local/jkzhao/softwares/miniconda3/envs/s3prl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/users/hccl.local/jkzhao/softwares/miniconda3/envs/s3prl/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading SemantiCodec encoder\n",
      "âœ… Encoder loaded\n",
      "ðŸš€ Loading SemantiCodec decoder\n",
      "DiffusionWrapper has 75.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/hccl.local/jkzhao/softwares/miniconda3/envs/s3prl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Decoder loaded\n"
     ]
    }
   ],
   "source": [
    "from semanticodec import SemantiCodec\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "semanticodec = SemantiCodec(token_rate=100, semantic_vocab_size=32768) # 1.40 kbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.76it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/mnt/users/hccl.local/jkzhao/projects/s3prl/test.wav\" # audio with arbitrary length\n",
    "\n",
    "tokens = semanticodec.encode(filepath)\n",
    "waveform = semanticodec.decode(tokens)\n",
    "\n",
    "# Save the reconstruction file\n",
    "import soundfile as sf\n",
    "sf.write(\"output.wav\", waveform[0,0], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = torch.rand(16, 2048, 128).to(\"cuda\")\n",
    "tokens = semanticodec.encoder(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticodec.utils import extract_kaldi_fbank_feature\n",
    "# Constants\n",
    "SAMPLE_RATE = 16000\n",
    "SEGMENT_DURATION = 10.24\n",
    "MEL_TARGET_LENGTH = 1024\n",
    "AUDIOMAE_PATCH_DURATION = 0.16\n",
    "SEGMENT_OVERLAP_RATIO = 0.0625\n",
    "\n",
    "class CodecWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CodecWrapper, self).__init__()\n",
    "        self.model = SemantiCodec(token_rate=100, semantic_vocab_size=32768) # 1.40 kbps\n",
    "        \n",
    "    def preprocess(self, waveform):\n",
    "        # waveform: (1, T), 16000Hz\n",
    "        sr = 16000\n",
    "        # if stereo to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform[0:1]\n",
    "        # Calculate the original duration\n",
    "        original_duration = waveform.shape[1] / sr\n",
    "        # This is to pad the audio to the multiplication of 0.16 seconds so that the original audio can be reconstructed\n",
    "        original_duration = original_duration + (\n",
    "            AUDIOMAE_PATCH_DURATION - original_duration % AUDIOMAE_PATCH_DURATION\n",
    "        )\n",
    "        # Calculate the token length in theory\n",
    "        target_token_len = (\n",
    "            8 * original_duration / AUDIOMAE_PATCH_DURATION / self.model.stack_factor_K\n",
    "        )\n",
    "        segment_sample_length = int(SAMPLE_RATE * SEGMENT_DURATION)\n",
    "        # Pad audio to the multiplication of 10.24 seconds for easier segmentations\n",
    "\n",
    "        if waveform.shape[1] % segment_sample_length < segment_sample_length:\n",
    "            waveform = torch.cat(\n",
    "                [\n",
    "                    waveform,\n",
    "                    torch.zeros(\n",
    "                        1,\n",
    "                        int(\n",
    "                            segment_sample_length\n",
    "                            - waveform.shape[1] % segment_sample_length\n",
    "                        ),\n",
    "                        device=waveform.device,\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "        mel_target_length = MEL_TARGET_LENGTH * int(\n",
    "            waveform.shape[1] / segment_sample_length\n",
    "        )\n",
    "        # Calculate the mel spectrogram\n",
    "        mel = extract_kaldi_fbank_feature(\n",
    "            waveform, sr, target_length=mel_target_length\n",
    "        )[\"ta_kaldi_fbank\"].unsqueeze(0)\n",
    "        mel = mel.squeeze(1)    # No use\n",
    "        assert mel.shape[-1] == 128 and mel.shape[-2] % 1024 == 0\n",
    "        return mel, target_token_len\n",
    "\n",
    "    def forward(self, wavs):\n",
    "        # mels = [self.preprocess(wav.unsqueeze(0))[0] for wav in wavs]\n",
    "        # mels = pad_sequence(mels, batch_first=True)\n",
    "        # print(mels.shape)\n",
    "        # # mels: (B, T, D), 16000Hz\n",
    "        # tokens = self.model.encoder(mels.to(self.model.device))\n",
    "        # latent = self.model.encoder.token_to_quantized_feature(tokens)\n",
    "        # return latent\n",
    "        for wav in wavs:\n",
    "            mel, target_token_len = self.preprocess(wav.unsqueeze(0))\n",
    "            tokens = self.model.encoder(mel.to(self.model.device))\n",
    "            latent = self.model.encoder.token_to_quantized_feature(tokens)\n",
    "            return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "# wav, sr = torchaudio.load(filepath)\n",
    "# wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "# wavs = [wav.squeeze(0).to(\"cuda\")]\n",
    "wavs = [torch.randn(16000).to(\"cuda\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading SemantiCodec encoder\n",
      "âœ… Encoder loaded\n",
      "ðŸš€ Loading SemantiCodec decoder\n",
      "DiffusionWrapper has 75.04 M params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/users/hccl.local/jkzhao/softwares/miniconda3/envs/s3prl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Decoder loaded\n"
     ]
    }
   ],
   "source": [
    "model = CodecWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model(wavs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
